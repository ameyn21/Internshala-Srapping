{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import utility libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing utility libraries\n",
    "\n",
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get HTML from the web page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://internshala.com/internships/data%20science-internship\"\n",
    "#conducting a request of the stated URL above:\n",
    "page = requests.get(URL)\n",
    "#specifying a desired format of “page” using the html parser - this allows python to read the various components of the page, rather than treating it as one long string.\n",
    "soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "#printing soup in a more structured tree format that makes for easier reading\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Job title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_job_title_from_result(job_div, job_post):    \n",
    "    for a in job_div.find(name=\"div\", attrs={\"class\":\"company\"}).find(name=\"div\", attrs={\"class\":\"profile\"}).find(name=\"a\"):\n",
    "        job_post.append(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Company name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_company_from_result(job_div, job_post): \n",
    "    for a in job_div.find(name=\"div\", attrs={\"class\":\"individual_internship_header\"}).find(name=\"div\", attrs={\"class\":\"company\"}).find(name=\"div\", attrs={\"class\":\"company_name\"}).find(name=\"a\"):\n",
    "        job_post.append(str(a).strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_location_from_result(job_div, job_post): \n",
    "    for a in job_div.find(name=\"div\", attrs={\"class\":\"individual_internship_details\"}).find(name=\"div\", attrs={\"id\":\"location_names\"}).find(name=\"a\", attrs={\"class\":\"location_link\"}):\n",
    "        job_post.append(str(a).strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_salary_from_result(job_div, job_post): \n",
    "    for stipend in job_div.find(name=\"div\", attrs={\"class\":\"individual_internship_details\"}).find(name=\"div\", attrs={\"class\":\"internship_other_details_container\"}).find(name=\"span\", attrs={\"class\":\"stipend\"}):        \n",
    "        if isinstance(stipend, bs4.element.NavigableString):\n",
    "            job_post.append(str(stipend).strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_duration_from_result(job_div, job_post): \n",
    "    for stipend in job_div.find(name=\"div\", attrs={\"class\":\"individual_internship_details\"}).find(name=\"div\", attrs={\"class\":\"internship_other_details_container\"}).find(name=\"span\", attrs={\"class\":\"stipend\"}):        \n",
    "        if isinstance(stipend, bs4.element.NavigableString):\n",
    "            job_post.append(str(stipend).strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### URL of Internships page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_URL_Of_page(base_url, skill):\n",
    "    return base_url + \"/internships/\" + skill + \"-internship\"    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_total_pages(url):\n",
    "    # get total number of pages\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.text, \"html.parser\", from_encoding=\"utf-8\")\n",
    "    total_pages = soup.find(name=\"span\", attrs={\"id\":\"total_pages\"})\n",
    "    return int(total_pages.text.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Internship Description page URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Internship_Description_Page_Url(job_div, base_url):\n",
    "    for a in job_div.find(name=\"div\", attrs={\"class\":\"button_container\"}).find_all(name=\"a\", attrs={\"class\":\"view_detail_button\"}, href=True):\n",
    "        return base_url + a['href']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_description_from_result(job_div, job_post):\n",
    "    page = requests.get(Get_Internship_Description_Page_Url(job_div, base_url))\n",
    "    soup_desc = BeautifulSoup(page.text, \"html.parser\", from_encoding=\"utf-8\")\n",
    "    \n",
    "    for div in soup_desc.find_all(name=\"div\", attrs={\"class\":\"section_heading heading_5_5\"}):\n",
    "        if any(word in div.text.strip() for word in [\"job/internship\", \"internship\", \"work from home\", \"part time\", \"job\"]):\n",
    "            job_post.append(div.next_sibling.next_sibling.text.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrap data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping code:\n",
    "columns = [\"job_title\", \"company_name\", \"location\", \"salary\", \"description\"]\n",
    "sample_df = pd.DataFrame(columns = columns)\n",
    "base_url = \"https://internshala.com\"\n",
    "skill = \"data science\"\n",
    "\n",
    "\n",
    "def Scrap_Internshala(base_url, skill):\n",
    "    url = Get_URL_Of_page(base_url, skill)\n",
    "    total_pages = Get_total_pages(url)\n",
    "    for page_number in range(total_pages):\n",
    "        page = requests.get(url + \"/page-\" + str(page_number + 1))\n",
    "        time.sleep(1)  #ensuring at least 1 second between page grabs\n",
    "        soup = BeautifulSoup(page.text, \"html.parser\", from_encoding=\"utf-8\")\n",
    "\n",
    "        for div in soup.find_all(name=\"div\", attrs={\"class\":\"individual_internship\"}): \n",
    "            #specifying row num for index of job posting in dataframe\n",
    "            num = (len(sample_df) + 1)\n",
    "            #creating an empty list to hold the data for each posting\n",
    "            job_post = []\n",
    "            #grabbing job title\n",
    "            extract_job_title_from_result(div, job_post)\n",
    "            #grabbing company name\n",
    "            extract_company_from_result(div, job_post)\n",
    "            #grabbing location name\n",
    "            extract_location_from_result(div, job_post)\n",
    "            #grabbing salary\n",
    "            extract_salary_from_result(div, job_post)\n",
    "            #grabbing internship description\n",
    "            extract_description_from_result(div, job_post)\n",
    "            #appending list of job post info to dataframe at index num\n",
    "            sample_df.loc[num] = job_post\n",
    "\n",
    "        #saving sample_df as a local csv file — define your own local path to save contents \n",
    "        sample_df.to_csv(\"job_scrapping_internshala.csv\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scrap_Internshala(base_url, skill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
